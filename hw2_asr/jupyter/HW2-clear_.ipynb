{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import jiwer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wandb.init(project=\"dla-asr-hw-2\", resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/home/veroslovets/dla/HW2/datasets/LJSpeech-1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_LJ(path):\n",
    "    latters = \"qwertyuiopasdfghjklzxcvbnm \"\n",
    "    id_latter = {}\n",
    "    latter_id = {}\n",
    "    for i, char in enumerate(latters):\n",
    "        id_latter[i] = char\n",
    "        latter_id[char] = i\n",
    "    \n",
    "    id_chars = []\n",
    "    values = {\"id\": [], \"text\": []}\n",
    "    with open(path + \"metadata.csv\", \"r\") as rdr:\n",
    "        for line in rdr:\n",
    "            line = line.split(\"|\")\n",
    "            sub_text = re.sub(r'[^a-z ]+', '', line[2].lower()[:-1])\n",
    "            values[\"text\"].append(sub_text)\n",
    "            values[\"id\"].append(line[0])\n",
    "            id_chars.append([latter_id[char] for char in sub_text])\n",
    "    \n",
    "    pd_values = pd.DataFrame(values)\n",
    "    pd_values[\"id_chars\"] = id_chars\n",
    "    \n",
    "    return pd_values, id_latter, latter_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, id_latter, latter_id = preprocessing_LJ(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, quantile=0.05):\n",
    "    lens = []\n",
    "    for i in df[\"text\"]:\n",
    "        lens.append(len(i))\n",
    "    l_ = np.quantile(lens, quantile)\n",
    "    r_ = np.quantile(lens, 1 - quantile)\n",
    "    mask = (df[\"text\"].str.len() > l_) & (df[\"text\"].str.len() < r_)\n",
    "    df = df[mask]\n",
    "    \n",
    "    return df, int(r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, max_seq_char = filter_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid_data = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, data, path, transform, pading_mel, padding_text):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path + \"wavs\"\n",
    "        self.transform = transform\n",
    "        self.pading_mel = pading_mel\n",
    "        self.padding_text = padding_text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        audio_name, _, tokens = self.data[index]\n",
    "        audio_path = os.path.join(self.path, audio_name + \".wav\")\n",
    "        wav, sr = torchaudio.load(audio_path)\n",
    "        wav = wav.squeeze()\n",
    "        mel_spectrogram = self.transform.forward(wav)\n",
    "        log_mel = torch.log(mel_spectrogram + 1e-9)\n",
    "        \n",
    "        if log_mel.shape[2 - 1] < self.pading_mel:\n",
    "            res = torch.cat((log_mel, torch.zeros((log_mel.shape[1 - 1],self.pading_mel-log_mel.shape[2- 1]))), dim=1)\n",
    "        else:\n",
    "            res = log_mel[:,:self.pading_mel]\n",
    "        \n",
    "        target = torch.tensor(tokens + [27] * (self.padding_text - len(tokens)))\n",
    "        target_len = torch.tensor(len(tokens))\n",
    "        input_len = torch.tensor(435)\n",
    "        \n",
    "        \n",
    "        return res.squeeze(0).transpose(0, 1), target, target_len, input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=64, n_fft=1024, hop_length=256, f_max=10000)\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    melspec,\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=10),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_text = 148\n",
    "batch_size   = 64\n",
    "padding_spec = 870\n",
    "melspec      = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=64, n_fft=1024, hop_length=256, f_max=10000)\n",
    "train_loader = DataLoader(dataset=LoadDataset(train, dir_path, train_audio_transforms, padding_spec, padding_text), batch_size = batch_size, shuffle=True, num_workers=3)\n",
    "valid_loader = DataLoader(dataset=LoadDataset(valid_data, dir_path, melspec, padding_spec, padding_text), batch_size = batch_size, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(2, 3).contiguous()\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.LSTM(input_size=rnn_dim, hidden_size=hidden_size, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim, n_classes, dropout):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.clf1 = nn.Linear(dim * 2, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.clf2 = nn.Linear(dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clf1(x)\n",
    "        x = self.drop(x)\n",
    "        return self.clf2(x)\n",
    "\n",
    "\n",
    "class SpeechRecognition(nn.Module):\n",
    "    def __init__(self, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognition, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)\n",
    "\n",
    "        self.rescnn_layers1 = ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "        self.rescnn_layers2 = ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "\n",
    "        self.birnn_layers = BidirectionalGRU(rnn_dim=rnn_dim, hidden_size=rnn_dim, dropout=dropout)\n",
    "\n",
    "        self.classifier = Classifier(rnn_dim, n_class, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers1(x)\n",
    "        x = self.rescnn_layers2(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechRecognition(128, 29, 64, 2, 0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_text(labels):\n",
    "    string = \"\"\n",
    "    for i in labels:\n",
    "        string += id_latter[i]\n",
    "    return string\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    \n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit-Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(start_time):\n",
    "    duration = datetime.now() - start_time\n",
    "    days, seconds = duration.days, duration.seconds\n",
    "    hours = days * 24 + seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    \n",
    "    return minutes, seconds\n",
    "\n",
    "\n",
    "def train_epoch(epoch, model, optimizer, criterion, batch_size):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = datetime.now()\n",
    "    for idx, (melspec, tokens, target_len, padded_len) in enumerate(train_loader):\n",
    "        melspec, tokens = melspec.to(device), tokens.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(melspec.unsqueeze(1).transpose(2, 3))\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        \n",
    "        loss = criterion(outputs.transpose(0, 1), tokens, padded_len, target_len)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        minutes,seconds = get_time(start_time)\n",
    "        \n",
    "        print(\"\\r Train Epoch {} [{}/{} ({:.0f}%)] loss: {:.7f} time: {}m:{}s\".format(epoch, \n",
    "                                                                                      (idx + 1) * batch_size,\n",
    "                                                                                      len(train_loader.dataset),\n",
    "                                                                                      100. * idx / len(train_loader),\n",
    "                                                                                      loss.item(),\n",
    "                                                                                      minutes,\n",
    "                                                                                      seconds), end='')\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            pass\n",
    "            #wandb.log({\"Loss\": loss})\n",
    "    print()\n",
    "\n",
    "def evaluate(model, criterion, calc_wer=False):\n",
    "    model.eval() \n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    test_cer = []\n",
    "    test_wer = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (melspec, tokens, target_len, padded_len) in enumerate(valid_loader):\n",
    "            melspec, tokens = melspec.to(device), tokens.to(device)\n",
    "\n",
    "            outputs = model(melspec.unsqueeze(1).transpose(2, 3))\n",
    "            outputs = F.log_softmax(outputs, dim=2)\n",
    "\n",
    "            loss += criterion(outputs.transpose(0, 1), tokens, padded_len, target_len).item()\n",
    "            \n",
    "            if calc_wer:\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(outputs, tokens, target_len)\n",
    "\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    test_wer.append(jiwer.wer(decoded_targets[j], decoded_preds[j]))\n",
    "    \n",
    "    loss /= len(valid_loader)\n",
    "    #wandb.log({\"Validation loss\": loss})\n",
    "    \n",
    "    if calc_wer:\n",
    "        avg_wer = sum(test_wer) / len(test_wer)\n",
    "        #wandb.log({\"WER\": avg_wer})\n",
    "        print('Validation: Average loss: {:.4f}, Average WER: {:.4f}\\n'.format(loss, avg_wer))\n",
    "    else:\n",
    "        print('Validation: Average loss: {:.4f}\\n'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch 1 [10560/10558 (99%)] loss: 2.8928115 time: 3m:21s\n",
      "Validation: Average loss: 2.8824\n",
      "\n",
      " Train Epoch 2 [10560/10558 (99%)] loss: 2.8859916 time: 3m:23s\n",
      "Validation: Average loss: 2.8705, Average WER: 1.0000\n",
      "\n",
      " Train Epoch 3 [10560/10558 (99%)] loss: 2.8238022 time: 3m:22s\n",
      "Validation: Average loss: 2.8319\n",
      "\n",
      " Train Epoch 4 [10560/10558 (99%)] loss: 2.0247285 time: 3m:22s\n",
      "Validation: Average loss: 1.9240, Average WER: 0.9779\n",
      "\n",
      " Train Epoch 5 [10560/10558 (99%)] loss: 1.2131670 time: 3m:22s\n",
      "Validation: Average loss: 1.0228\n",
      "\n",
      " Train Epoch 6 [10560/10558 (99%)] loss: 0.8984979 time: 3m:22s\n",
      "Validation: Average loss: 0.7314, Average WER: 0.6883\n",
      "\n",
      " Train Epoch 7 [10560/10558 (99%)] loss: 0.8028217 time: 3m:22s\n",
      "Validation: Average loss: 0.5919\n",
      "\n",
      " Train Epoch 8 [10560/10558 (99%)] loss: 0.6509426 time: 3m:23s\n",
      "Validation: Average loss: 0.5127, Average WER: 0.5635\n",
      "\n",
      " Train Epoch 9 [10560/10558 (99%)] loss: 0.6084922 time: 3m:22s\n",
      "Validation: Average loss: 0.4526\n",
      "\n",
      " Train Epoch 10 [10560/10558 (99%)] loss: 0.5544512 time: 3m:22s\n",
      "Validation: Average loss: 0.4129, Average WER: 0.4745\n",
      "\n",
      " Train Epoch 11 [10560/10558 (99%)] loss: 0.5269333 time: 3m:22s\n",
      "Validation: Average loss: 0.3812\n",
      "\n",
      " Train Epoch 12 [10560/10558 (99%)] loss: 0.4980358 time: 3m:22s\n",
      "Validation: Average loss: 0.3501, Average WER: 0.4196\n",
      "\n",
      " Train Epoch 13 [10560/10558 (99%)] loss: 0.4805636 time: 3m:22s\n",
      "Validation: Average loss: 0.3261\n",
      "\n",
      " Train Epoch 14 [10560/10558 (99%)] loss: 0.4486903 time: 3m:22s\n",
      "Validation: Average loss: 0.3120, Average WER: 0.3800\n",
      "\n",
      " Train Epoch 15 [10560/10558 (99%)] loss: 0.4280492 time: 3m:22s\n",
      "Validation: Average loss: 0.2954\n",
      "\n",
      " Train Epoch 16 [10560/10558 (99%)] loss: 0.4008003 time: 3m:22s\n",
      "Validation: Average loss: 0.2852, Average WER: 0.3506\n",
      "\n",
      " Train Epoch 17 [10560/10558 (99%)] loss: 0.3850622 time: 3m:22s\n",
      "Validation: Average loss: 0.2713\n",
      "\n",
      " Train Epoch 18 [10560/10558 (99%)] loss: 0.3458949 time: 3m:23s\n",
      "Validation: Average loss: 0.2633, Average WER: 0.3253\n",
      "\n",
      " Train Epoch 19 [10560/10558 (99%)] loss: 0.3316128 time: 3m:21s\n",
      "Validation: Average loss: 0.2530\n",
      "\n",
      " Train Epoch 20 [10560/10558 (99%)] loss: 0.3468533 time: 3m:22s\n",
      "Validation: Average loss: 0.2476, Average WER: 0.3060\n",
      "\n",
      " Train Epoch 21 [10560/10558 (99%)] loss: 0.2885852 time: 3m:22s\n",
      "Validation: Average loss: 0.2354\n",
      "\n",
      " Train Epoch 22 [10560/10558 (99%)] loss: 0.3340778 time: 3m:23s\n",
      "Validation: Average loss: 0.2311, Average WER: 0.2871\n",
      "\n",
      " Train Epoch 23 [10560/10558 (99%)] loss: 0.2956822 time: 3m:22s\n",
      "Validation: Average loss: 0.2203\n",
      "\n",
      " Train Epoch 24 [10560/10558 (99%)] loss: 0.2567044 time: 3m:22s\n",
      "Validation: Average loss: 0.2187, Average WER: 0.2753\n",
      "\n",
      " Train Epoch 25 [10560/10558 (99%)] loss: 0.2882231 time: 3m:22s\n",
      "Validation: Average loss: 0.2163\n",
      "\n",
      " Train Epoch 26 [10560/10558 (99%)] loss: 0.3386104 time: 3m:23s\n",
      "Validation: Average loss: 0.2155, Average WER: 0.2711\n",
      "\n",
      " Train Epoch 27 [10560/10558 (99%)] loss: 0.2655677 time: 3m:22s\n",
      "Validation: Average loss: 0.2097\n",
      "\n",
      " Train Epoch 28 [10560/10558 (99%)] loss: 0.2470191 time: 3m:23s\n",
      "Validation: Average loss: 0.2048, Average WER: 0.2545\n",
      "\n",
      " Train Epoch 29 [10560/10558 (99%)] loss: 0.2297654 time: 3m:22s\n",
      "Validation: Average loss: 0.2015\n",
      "\n",
      " Train Epoch 30 [10560/10558 (99%)] loss: 0.2306851 time: 3m:23s\n",
      "Validation: Average loss: 0.1949, Average WER: 0.2419\n",
      "\n",
      " Train Epoch 31 [10560/10558 (99%)] loss: 0.2295993 time: 3m:22s\n",
      "Validation: Average loss: 0.1992\n",
      "\n",
      " Train Epoch 32 [10560/10558 (99%)] loss: 0.2521470 time: 3m:23s\n",
      "Validation: Average loss: 0.1971, Average WER: 0.2445\n",
      "\n",
      " Train Epoch 33 [10560/10558 (99%)] loss: 0.2039898 time: 3m:22s\n",
      "Validation: Average loss: 0.1933\n",
      "\n",
      " Train Epoch 34 [10560/10558 (99%)] loss: 0.2357398 time: 3m:23s\n",
      "Validation: Average loss: 0.1903, Average WER: 0.2349\n",
      "\n",
      " Train Epoch 35 [10560/10558 (99%)] loss: 0.2210179 time: 3m:22s\n",
      "Validation: Average loss: 0.1858\n",
      "\n",
      " Train Epoch 36 [10560/10558 (99%)] loss: 0.2035326 time: 3m:23s\n",
      "Validation: Average loss: 0.1868, Average WER: 0.2264\n",
      "\n",
      " Train Epoch 37 [10560/10558 (99%)] loss: 0.1860058 time: 3m:22s\n",
      "Validation: Average loss: 0.1848\n",
      "\n",
      " Train Epoch 38 [10560/10558 (99%)] loss: 0.1888703 time: 3m:23s\n",
      "Validation: Average loss: 0.1869, Average WER: 0.2274\n",
      "\n",
      " Train Epoch 39 [10560/10558 (99%)] loss: 0.1658381 time: 3m:22s\n",
      "Validation: Average loss: 0.1855\n",
      "\n",
      " Train Epoch 40 [10560/10558 (99%)] loss: 0.1818045 time: 3m:23s\n",
      "Validation: Average loss: 0.1805, Average WER: 0.2217\n",
      "\n",
      " Train Epoch 41 [10560/10558 (99%)] loss: 0.1900830 time: 3m:22s\n",
      "Validation: Average loss: 0.1816\n",
      "\n",
      " Train Epoch 42 [10560/10558 (99%)] loss: 0.1843333 time: 3m:23s\n",
      "Validation: Average loss: 0.1794, Average WER: 0.2143\n",
      "\n",
      " Train Epoch 43 [10560/10558 (99%)] loss: 0.2072473 time: 3m:22s\n",
      "Validation: Average loss: 0.1764\n",
      "\n",
      " Train Epoch 44 [10560/10558 (99%)] loss: 0.2000529 time: 3m:22s\n",
      "Validation: Average loss: 0.1805, Average WER: 0.2163\n",
      "\n",
      " Train Epoch 45 [10560/10558 (99%)] loss: 0.1710393 time: 3m:22s\n",
      "Validation: Average loss: 0.1774\n",
      "\n",
      " Train Epoch 46 [10560/10558 (99%)] loss: 0.1713440 time: 3m:22s\n",
      "Validation: Average loss: 0.1801, Average WER: 0.2118\n",
      "\n",
      " Train Epoch 47 [10560/10558 (99%)] loss: 0.1779901 time: 3m:22s\n",
      "Validation: Average loss: 0.1758\n",
      "\n",
      " Train Epoch 48 [10560/10558 (99%)] loss: 0.1816223 time: 3m:23s\n",
      "Validation: Average loss: 0.1718, Average WER: 0.2001\n",
      "\n",
      " Train Epoch 49 [10560/10558 (99%)] loss: 0.1664926 time: 3m:22s\n",
      "Validation: Average loss: 0.1759\n",
      "\n",
      " Train Epoch 50 [10560/10558 (99%)] loss: 0.1721583 time: 3m:22s\n",
      "Validation: Average loss: 0.1764, Average WER: 0.2038\n",
      "\n",
      " Train Epoch 51 [10560/10558 (99%)] loss: 0.1525098 time: 3m:22s\n",
      "Validation: Average loss: 0.1754\n",
      "\n",
      " Train Epoch 52 [10560/10558 (99%)] loss: 0.1275641 time: 3m:22s\n",
      "Validation: Average loss: 0.1744, Average WER: 0.1975\n",
      "\n",
      " Train Epoch 53 [10560/10558 (99%)] loss: 0.1496461 time: 3m:22s\n",
      "Validation: Average loss: 0.1719\n",
      "\n",
      " Train Epoch 54 [10560/10558 (99%)] loss: 0.1386726 time: 3m:22s\n",
      "Validation: Average loss: 0.1716, Average WER: 0.1920\n",
      "\n",
      " Train Epoch 55 [10560/10558 (99%)] loss: 0.1481136 time: 3m:22s\n",
      "Validation: Average loss: 0.1727\n",
      "\n",
      " Train Epoch 56 [10560/10558 (99%)] loss: 0.1654473 time: 3m:23s\n",
      "Validation: Average loss: 0.1703, Average WER: 0.1941\n",
      "\n",
      " Train Epoch 57 [10560/10558 (99%)] loss: 0.1861082 time: 3m:22s\n",
      "Validation: Average loss: 0.1707\n",
      "\n",
      " Train Epoch 58 [10560/10558 (99%)] loss: 0.1475733 time: 3m:22s\n",
      "Validation: Average loss: 0.1754, Average WER: 0.1950\n",
      "\n",
      " Train Epoch 59 [10560/10558 (99%)] loss: 0.1543893 time: 3m:22s\n",
      "Validation: Average loss: 0.1722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 60\n",
    "for i in range(1, num_epoch):\n",
    "    train_epoch(i, model, optimizer, criterion, batch_size)\n",
    "    if i % 2 == 0:\n",
    "        evaluate(model, criterion, calc_wer=True)\n",
    "    else:\n",
    "        evaluate(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-de191f53719d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': num_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': 0.1722,\n",
    "            }, \"model.checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW2-assemblyai.ipynb\tUntitled.ipynb\t   model.checkpoint.pth\r\n",
      "HW2-clear_.ipynb\tdata\t\t   test-clean.tar.gz\r\n",
      "HW_2_RUSSION_ASR.ipynb\tdatasets\t   train-clean-100.tar.gz\r\n",
      "LibriSpeech\t\thomework2_M.ipynb  wandb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechRecognition(\n",
       "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (rescnn_layers1): ResidualCNN(\n",
       "    (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm1): CNNLayerNorm(\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm2): CNNLayerNorm(\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers2): ResidualCNN(\n",
       "    (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm1): CNNLayerNorm(\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm2): CNNLayerNorm(\n",
       "      (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fully_connected): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (birnn_layers): BidirectionalGRU(\n",
       "    (BiGRU): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (clf1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (clf2): Linear(in_features=128, out_features=29, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = SpeechRecognition(128, 29, 64, 2, 0.1)\n",
    "#optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(\"model.checkpoint.pth\")\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Average loss: 0.1722, Average WER: 0.1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model2, criterion, calc_wer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: and we have every reason to believe that it should be in full swing by autumn\n",
      "PREDICT and we have every reason to believe that it should be infulswiing by auhtoum\n",
      "--------------------------------------------\n",
      "TRUE: after inspecting this floor sawyer returned to the street about three minutes after he entered the building\n",
      "PREDICT after inspecting this floor sowier returned to the street about three minutes after he entered the building\n",
      "--------------------------------------------\n",
      "TRUE: great efforts have been made to save his life\n",
      "PREDICT great efforts have been made to sa his life\n",
      "--------------------------------------------\n",
      "TRUE: field labor he urged and with reason was a very suitable employment\n",
      "PREDICT field labor he urdged and with reason was a very sutable employment\n",
      "--------------------------------------------\n",
      "TRUE: the crowding was in consequence of the delay in removing transports\n",
      "PREDICT the crowding was in consequence of the delay in removing transports\n",
      "--------------------------------------------\n",
      "TRUE: would be consistent with the period when the oswalds were living on neely street since the apartment was rented on march three nineteen sixtythree\n",
      "PREDICT would be consistent with the period when the oswalds reliving on neely street since the apartment was rented on march three nineteen sixtythree\n",
      "--------------------------------------------\n",
      "TRUE: idleness was still the general rule for all prisoners in newgate in defiance of the law\n",
      "PREDICT idleness was still the genral rule for all prisoners in newgate in defincs of the law\n",
      "--------------------------------------------\n",
      "TRUE: dove a fiendish brute found from the evidence in that case that he could kill his wife whom he hated\n",
      "PREDICT dove o findishe brot found from the evidencein that case that he could kill his wife whom he hated\n",
      "--------------------------------------------\n",
      "TRUE: in this convulsive struggle for bare existence people fought fiercely with one another and the weakest of course the women went under\n",
      "PREDICT in this convulsive struggle for bar existance people fought fiersly with one another and the weakest course the women went under\n",
      "--------------------------------------------\n",
      "TRUE: the human hand that placed it there was only seen for a moment\n",
      "PREDICT the houman hand that placed at there was only seen for a moment\n",
      "--------------------------------------------\n",
      "TRUE: that the fbi took an unduly restrictive view of its responsibilities in preventive intelligence work prior to the assassination\n",
      "PREDICT that the fbi to kan unduly restrictive view of its responsibilties in preventive intelligence work prior to the assassination\n",
      "--------------------------------------------\n",
      "TRUE: and their foreign journeys have come to be accepted as normal rather than extraordinary\n",
      "PREDICT and their foreran journeys have come to be accepted as normal rather than iextradinary\n",
      "--------------------------------------------\n",
      "TRUE: but mr pearson hardly considered the converse sufficiently and\n",
      "PREDICT but mr pearse in hardly considered the converse sufficiently and\n",
      "--------------------------------------------\n",
      "TRUE: on that account he made no provision to insure safe custody\n",
      "PREDICT on that account he made no provision to insure safe custody\n",
      "--------------------------------------------\n",
      "TRUE: as a result of the investigation he ordered he was satisfied that each of the agents performed his duties in an entirely satisfactory manner\n",
      "PREDICT as a result of the investigation he ordered he was satisfied that each of the agents performed his duties in an entirely satisfactory manner\n",
      "--------------------------------------------\n",
      "TRUE: these bankers wishing for more specific information\n",
      "PREDICT these bankers wishing for mor sepecific information\n",
      "--------------------------------------------\n",
      "TRUE: highway robberies for instance had disappeared if we except the spasmodic and severely repressed outbreak of garotting\n",
      "PREDICT highwa robberies frinstance had disappeared if we except the spes mt i an severely repressed outbrak of ghariting\n",
      "--------------------------------------------\n",
      "TRUE: none of the stolen paper was glazed and this was an important clue to the subsequent discovery of the crime\n",
      "PREDICT none of the stolen paper was glased and this was an important cle to the subsequent discovery of the crime\n",
      "--------------------------------------------\n",
      "TRUE: the prison stood on a dry airy situation outside the town\n",
      "PREDICT the prison stod on a dry airesituation outside the town\n",
      "--------------------------------------------\n",
      "TRUE: his account of his acts and movements after the deed\n",
      "PREDICT his acount of his acts and ovements after the deed\n",
      "--------------------------------------------\n",
      "TRUE: mrs kennedy then heard a second shot and saw the presidents skull torn open under the impact of the bullet\n",
      "PREDICT mrs kennedy then hard a second shot and saw the presidents skule torn open under the impact of the bullet\n",
      "--------------------------------------------\n",
      "TRUE: i think all of those if we had them all together\n",
      "PREDICT it the gall osose if we had the malltogether\n",
      "--------------------------------------------\n",
      "TRUE: the inspectors reports mention many cases of evasion accomplished\n",
      "PREDICT the inspectors reports mention many cases of avaion accomplished\n",
      "--------------------------------------------\n",
      "TRUE: or class one with whom under the imperious demand for accommodation were also associated the misdemeanants or class two\n",
      "PREDICT or class one with whom under the imperious demand for accommodation were also associated the misdemenants or cless two\n",
      "--------------------------------------------\n",
      "TRUE: three other officers moving toward the scuffle grabbed oswald from the front rear and side\n",
      "PREDICT three other officers moving toward the sculffle grabed oswald from the front rear and side\n",
      "--------------------------------------------\n",
      "TRUE: nine minutes later the presidential airplane departed for washington dc\n",
      "PREDICT nine minutes later the presidential airplanedeparted for washingtondc\n",
      "--------------------------------------------\n",
      "TRUE: but in his testimony before the commission brennan stated that his remarks of january seven were intended by him merely as an accurate report\n",
      "PREDICT but in his testimony before the commission brennan stated that his remarks of january seven were intended by him merely as an accurate report\n",
      "--------------------------------------------\n",
      "TRUE: all the committee could do in this respect was to throw the responsibility on others\n",
      "PREDICT all the committee could du in this respect was to throw the responsibility on others\n",
      "--------------------------------------------\n",
      "TRUE: next day a person betrayed him for the reward and he was soon captured\n",
      "PREDICT next day a person betraed him for the reward and he was soon captiue\n",
      "--------------------------------------------\n",
      "TRUE: the crime of poisoning has always been viewed with peculiar loathing and terror in this country\n",
      "PREDICT the crime of poisoning has always been viewed with peculigar lothing and terror in this country\n",
      "--------------------------------------------\n",
      "TRUE: and in the history of his life which does give some insight into his character and possibly into the motives for his act\n",
      "PREDICT and in the histry of his life which duz give some insit intoose character and possibly into the motivesfore his act\n",
      "--------------------------------------------\n",
      "TRUE: the same callous indifference to the moral wellbeing of the prisoners the same want of employment and of all disciplinary control\n",
      "PREDICT the same callius indifference to the moral wellbeing of the prisoners the same want of enployment and of all disciplinary controll\n",
      "--------------------------------------------\n",
      "TRUE: while behind their pew stood a couple of tall footmen in state liveries\n",
      "PREDICT while behind theire pew sto d a couple of tall fotmen in state liveries\n",
      "--------------------------------------------\n",
      "TRUE: for the threemonth period prior to the assassination reflects an extremely critical attitude toward president kennedy and his administration\n",
      "PREDICT for the three month period prior to the assassination reflecs in extremely chrindical aditude tord president kennedy and is administration\n",
      "--------------------------------------------\n",
      "TRUE: quote i knew there was no such organization and i know hidell is merely an altered fidel and i laughed at such foolishness\n",
      "PREDICT quote a knew there was no such orgnization and i kno hidell is merely an altered fidell and i lafht at sich foolishness\n",
      "--------------------------------------------\n",
      "TRUE: there may be occasional instances of inefficiency bad management or misuse of funds\n",
      "PREDICT there may be occasional istances of inefficiency bad management or missuse of funds\n",
      "--------------------------------------------\n",
      "TRUE: so i gave her a transfer and opened the door and she was going out the gentleman i had picked up about two blocks back\n",
      "PREDICT so i gave or a transfer and open the door and she was going out the jentle man i had picked o about two blocks back\n",
      "--------------------------------------------\n",
      "TRUE: two other witnesses sam guinyard and william arthur smith\n",
      "PREDICT two other witnesses sam guinard and william arthur smith\n",
      "--------------------------------------------\n",
      "TRUE: while quote resourcefulness and patient working towards the aforesaid goals\n",
      "PREDICT while quote resourcefulness and patcient working towards the affore said gols\n",
      "--------------------------------------------\n",
      "TRUE: maintains records of people who have threatened the president or so conducted themselves as to be deemed a potential danger to him\n",
      "PREDICT maintains records of people who have threten the president or so conducted themselves as to be deemed a potential danger to hinm\n",
      "--------------------------------------------\n",
      "TRUE: two bow street runners were dispatched to the house in york street which had evidently been taken on purpose for the outrage\n",
      "PREDICT two bo street runners were dispatch to the house in york street which had evidently been taken on purpose for the outrage\n",
      "--------------------------------------------\n",
      "TRUE: and that is the last i have seen or spoken with oswald end quote\n",
      "PREDICT and that is the last i have seen or spoken with oswald end quote\n",
      "--------------------------------------------\n",
      "TRUE: passed the intersection of tenth and patton about eight blocks from where he had reported at twelvefiftyfour pm\n",
      "PREDICT passed the intersection of tenth and patton about eight blocks from where he had reported at twelvefiftyfour pm\n",
      "--------------------------------------------\n",
      "TRUE: to murphy and elm three times averaging six point five minutes for the three trips\n",
      "PREDICT to merfhy an elm three times averaging six point five minutes for the three trips\n",
      "--------------------------------------------\n",
      "TRUE: the man of better birth could hope for no sympathy whatever his crime\n",
      "PREDICT the man of better birth could hope for no sympathywhat ever his crime\n",
      "--------------------------------------------\n",
      "TRUE: in such a way that tester had possession of this key for a time\n",
      "PREDICT insushalway that tester had possession of this kiy for a time\n",
      "--------------------------------------------\n",
      "TRUE: through the bars of which quills or reeds were inserted and drink conveyed to the prisoners\n",
      "PREDICT through the bars of which quills or reds were inserted and drink conveyed to the prisoners\n",
      "--------------------------------------------\n",
      "TRUE: on august twentyone nineteen sixtythree bureau headquarters instructed the new orleans and dallas field offices\n",
      "PREDICT on augus twentyone nineteen sixtythree bureau headquarters instructed the new orleans in dallas field offices\n",
      "--------------------------------------------\n",
      "TRUE: though now extinct species speaks strongly in favor of evolution\n",
      "PREDICT thoughnow extenct species speak strongly in favor ovevolution\n",
      "--------------------------------------------\n",
      "TRUE: he left newgate utterly corrupted and after lapsing into crime soon returned with a very different character\n",
      "PREDICT he left newgate utterly corupted and after lapsing into crime soon returnd with a very different character\n",
      "--------------------------------------------\n",
      "TRUE: the poor creature was never seen again alive\n",
      "PREDICT the por creature was never seenagain alive\n",
      "--------------------------------------------\n",
      "TRUE: some jurisdictions greatly to their credit strove at once to follow the lead of the central authority\n",
      "PREDICT sum jurisdictions greaktly to their credit strove at wonts to followe delied of the central uthority\n",
      "--------------------------------------------\n",
      "TRUE: his method was comprehensive and deeply laid\n",
      "PREDICT his metheit was comprehensive and deeply laed\n",
      "--------------------------------------------\n",
      "TRUE: refuted by abundant evidence and having no foundation whatever in truth\n",
      "PREDICT refuted by a bundant evidence and having no foundation whatever intruoth\n",
      "--------------------------------------------\n",
      "TRUE: the roof of the female prison says the grand jury in their presentment in eighteen thirteen let in the rain\n",
      "PREDICT the roopfh of the female prisonsas the grandjury in their present ment in eighteen thirteen lett in the rain\n",
      "--------------------------------------------\n",
      "TRUE: where he did as he wanted and he didnt have to live by any rules or come into contact with people end quote\n",
      "PREDICT where he did as he wanted and y didnt have de live by any rules or com into contect with people end quote\n",
      "--------------------------------------------\n",
      "TRUE: its efforts appear to have been too largely directed at the crank threat\n",
      "PREDICT its efforts appear to ave been to  largely directed at the crank threat\n",
      "--------------------------------------------\n",
      "TRUE: already a strong dislike to the reckless and almost indiscriminate application of the extreme penalty was apparent in all classes\n",
      "PREDICT allready a strong disligke to the reckless and almst indiscriminate applcation of the extreme penalty was apparent in all classes\n",
      "--------------------------------------------\n",
      "TRUE: of course the theory of descent with adaptive modification has a simple answer to supply\n",
      "PREDICT of course the hery of decent with adaptive modification has a simple answer to supply\n",
      "--------------------------------------------\n",
      "TRUE: can lead to lapses in protection such as the confusion in dallas about whether members of the public were permitted on overpasses\n",
      "PREDICT candly to laps is in protection such as the confusion in dallas about whether members of the public were permitted on overpasses\n",
      "--------------------------------------------\n",
      "TRUE: under these circumstances unnatural as they are with proper management the bean will thrust forth its radicle and its plumule\n",
      "PREDICT under these circumstances unnatural as they are with proper management the ben will thrust fort hits radical and its plomule\n",
      "--------------------------------------------\n",
      "TRUE: and creeping out into the garden at the back climbed the wall and got into the street\n",
      "PREDICT and creping out into the garden at the back climed the wall and got into thi street\n",
      "--------------------------------------------\n",
      "TRUE: edmund angelini to take fauntleroys place\n",
      "PREDICT edmined angeleny to take funttheroise place\n",
      "--------------------------------------------\n",
      "TRUE: the worker replied quote your kind offer is most welcomed and from time to time we shall call on you end quote\n",
      "PREDICT the worker replied quote yeurkind affter is most welcomed and fromtime tho time we shal call on you end quote\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (melspec, tokens, target_len, padded_len) in enumerate(valid_loader):\n",
    "        melspec, tokens = melspec.to(device), tokens.to(device)\n",
    "\n",
    "        outputs = model(melspec.unsqueeze(1).transpose(2, 3))\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "\n",
    "        \n",
    "        decoded_preds, decoded_targets = GreedyDecoder(outputs, tokens, target_len)\n",
    "\n",
    "        for j in range(len(decoded_preds)):\n",
    "            print(\"TRUE:\", decoded_targets[j])\n",
    "            print(\"PREDICT\", decoded_preds[j])\n",
    "            print(\"--------------------------------------------\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
